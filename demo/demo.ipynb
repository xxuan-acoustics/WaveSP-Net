{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0710705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display, Markdown\n",
    "from huggingface_hub import hf_hub_download\n",
    "import ipywidgets as widgets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c605e",
   "metadata": {},
   "source": [
    "#### Step 1ï¼š Load the WaveSP-Net model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae27c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import WaveSP_Net\n",
    "\n",
    "ckpt_path = hf_hub_download(\n",
    "    repo_id=\"xxuan-speech/WaveSP-Net\",\n",
    "    filename=\"WaveSP-Net.pt\"\n",
    ")\n",
    "\n",
    "model = WaveSP_Net(model_dir=\"/home/xxuan/pre-model/huggingface/wav2vec2-xls-r-300m/\", \n",
    "                   prompt_dim=1024,\n",
    "                   num_prompt_tokens = 6,\n",
    "                   num_wavlet_tokens = 4,\n",
    "                   dropout= 0.1).cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=\"cpu\"), strict=False)\n",
    "model.eval()\n",
    "print(\"WaveSP-Net Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f8079",
   "metadata": {},
   "source": [
    "#### Step 2: Load Real and Fake audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7efe6527e3e4b26b421b18e23cf53bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Real'), Output(), Output(layout=Layout(width='500px')), Output(layoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_audio(wav_path):\n",
    "    waveform, sr = torchaudio.load(wav_path)\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    if sr != 16000:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "        sr = 16000\n",
    "    if waveform.ndim == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "    return waveform, sr\n",
    "\n",
    "# Paths\n",
    "real_wav_path = \"./demo/Real0001.wav\"\n",
    "fake_wav_path = \"./demo/Fake0001.wav\"\n",
    "\n",
    "real_audio, sr = preprocess_audio(real_wav_path)\n",
    "fake_audio, _ = preprocess_audio(fake_wav_path)\n",
    "\n",
    "\n",
    "def draw_waveform(waveform, sr, title=\"Waveform\"):\n",
    "    waveform = waveform.squeeze().numpy()\n",
    "    time = np.arange(0, len(waveform)) / sr\n",
    "    plt.figure(figsize=(5, 1.6))\n",
    "    plt.plot(time, waveform, linewidth=0.8, color='steelblue')\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(title, fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def draw_spectrogram(waveform, sr, title=\"Spectrogram\"):\n",
    "    waveform = waveform.squeeze().numpy()\n",
    "    spec = torchaudio.transforms.Spectrogram(n_fft=1024, hop_length=256)(torch.tensor(waveform))\n",
    "    spec = torch.log(spec + 1e-9)\n",
    "    plt.figure(figsize=(5, 1.6))\n",
    "    plt.imshow(spec.numpy(), aspect='auto', origin='lower', cmap='magma')\n",
    "    plt.xlabel(\"Time Frame\")\n",
    "    plt.ylabel(\"Frequency Bin\")\n",
    "    plt.title(title, fontsize=10)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def make_plot_output(plot_func, waveform, sr, title):\n",
    "    out = widgets.Output(layout={'width': '500px'})\n",
    "    with out:\n",
    "        plot_func(waveform, sr, title)\n",
    "    return out\n",
    "\n",
    "\n",
    "real_audio_out = widgets.Output()\n",
    "fake_audio_out = widgets.Output()\n",
    "\n",
    "with real_audio_out:\n",
    "    display(Audio(real_audio, rate=sr, autoplay=False))\n",
    "with fake_audio_out:\n",
    "    display(Audio(fake_audio, rate=sr, autoplay=False))\n",
    "\n",
    "\n",
    "real_wf_out = make_plot_output(draw_waveform, real_audio, sr, \"Real - Waveform\")\n",
    "fake_wf_out = make_plot_output(draw_waveform, fake_audio, sr, \"Fake - Waveform\")\n",
    "\n",
    "real_sp_out = make_plot_output(draw_spectrogram, real_audio, sr, \"Real - Spectrogram\")\n",
    "fake_sp_out = make_plot_output(draw_spectrogram, fake_audio, sr, \"Fake - Spectrogram\")\n",
    "\n",
    "\n",
    "real_col = widgets.VBox([\n",
    "    widgets.Label(\"Real\", layout=widgets.Layout(font_weight='bold')),\n",
    "    real_audio_out,\n",
    "    real_wf_out,\n",
    "    real_sp_out\n",
    "], layout=widgets.Layout(padding='10px', border='1px solid #ddd'))\n",
    "\n",
    "fake_col = widgets.VBox([\n",
    "    widgets.Label(\"Fake\", layout=widgets.Layout(font_weight='bold')),\n",
    "    fake_audio_out,\n",
    "    fake_wf_out,\n",
    "    fake_sp_out\n",
    "], layout=widgets.Layout(padding='10px', border='1px solid #ddd'))\n",
    "\n",
    "\n",
    "display(widgets.HBox([real_col, fake_col], layout=widgets.Layout(align_items='flex-start', gap='20px')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e34508",
   "metadata": {},
   "source": [
    "#### Step 3ï¼š Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e2202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### ðŸ”¹ Real0001.wav - Prediction: `real` - Fake Probability: 0.032278"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### ðŸ”¸ Fake0001.wav - Prediction: `fake` - Fake Probability: 0.827179"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Ensure model is in eval mode and on correct device\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# Inference on real_audio\n",
    "# -------------------------\n",
    "waveform = real_audio.clone() \n",
    "\n",
    "max_len = 64000\n",
    "if waveform.shape[1] > max_len:\n",
    "    waveform = waveform[:, :max_len]\n",
    "else:\n",
    "    waveform = torch.nn.functional.pad(waveform, (0, max_len - waveform.shape[1]))\n",
    "\n",
    "waveform = waveform.to(next(model.parameters()).device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, logits = model(waveform)\n",
    "\n",
    "probs = F.softmax(logits, dim=1)\n",
    "real_fake_prob = probs[0, 1].item()\n",
    "real_pred = \"fake\" if real_fake_prob > 0.5 else \"real\"\n",
    "\n",
    "# -------------------------\n",
    "# Inference on fake_audio\n",
    "# -------------------------\n",
    "waveform = fake_audio.clone()\n",
    "\n",
    "if waveform.shape[1] > max_len:\n",
    "    waveform = waveform[:, :max_len]\n",
    "else:\n",
    "    waveform = torch.nn.functional.pad(waveform, (0, max_len - waveform.shape[1]))\n",
    "\n",
    "waveform = waveform.to(next(model.parameters()).device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, logits = model(waveform)\n",
    "\n",
    "probs = F.softmax(logits, dim=1)\n",
    "fake_fake_prob = probs[0, 1].item()\n",
    "fake_pred = \"fake\" if fake_fake_prob > 0.5 else \"real\"\n",
    "\n",
    "# -------------------------\n",
    "# Display results\n",
    "# -------------------------\n",
    "display(Markdown(f\"##### ðŸ”¹ Real0001.wav - Prediction: `{real_pred}` - Fake Probability: {real_fake_prob:.6f}\"))\n",
    "display(Markdown(f\"##### ðŸ”¸ Fake0001.wav - Prediction: `{fake_pred}` - Fake Probability: {fake_fake_prob:.6f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b449d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
